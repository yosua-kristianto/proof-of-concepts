{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC-GAN (Deep Convolutional Generative Adversarial Network)\n",
    "\n",
    "I recently opened Tensorflow's tutorials on GAN (Generative Adversarial Network), and found this [link](https://www.tensorflow.org/tutorials/generative/dcgan). \n",
    "\n",
    "Basically the tutorial is making a generative handwritten digits image using Keras API. But in here, I'm gonna using TensorLayerX's API to build the GAN. Some parts may not following the Tensorflow's tutorial directly. \n",
    "\n",
    "Things to install:\n",
    "- tensorflow\n",
    "- tensorlayerx\n",
    "- torch (Just if you need it's backend. If not, you can skip torch)\n",
    "- matplotlib\n",
    "- numpy\n",
    "- pillow\n",
    "\n",
    "The goal here is to make a generative model that generates new handwritten digit images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow;\n",
    "from tensorflow.keras.datasets import mnist;\n",
    "import numpy;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch;\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading & Pre-Processing\n",
    "\n",
    "MNIST dataset is a database of handwritten digits for training. So people will type in 0 to 9 handwrittenly, taking the photo of it, and resizing it to 28 x 28 greyscale pixels.\n",
    "\n",
    "Tensorflow Keras API had an API to download MNIST dataset, and using it directly as train-test splits. If I'm not mistaken, TensorLayerX also had one, but I prefered this one since I once use it.\n",
    "\n",
    "By applying `.shape`, we can then see that by default, the training set had 60K worth of data while test set had 10K. From these 10K set, I split the test set into 50:50, making validation set from it.\n",
    "\n",
    "| Splits | Total data |\n",
    "|---|---|\n",
    "| Train | 60000 |\n",
    "| Test | 5000 |\n",
    "| Val | 5000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (5000, 28, 28), (5000, 28, 28))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data();\n",
    "\n",
    "# Split the test and val by 50:50\n",
    "test_val_images_split = numpy.array_split(test_images, 2);\n",
    "test_val_labels_split = numpy.array_split(test_labels, 2);\n",
    "\n",
    "test_images = test_val_images_split[0];\n",
    "test_labels = test_val_labels_split[0];\n",
    "\n",
    "val_images = test_val_images_split[1];\n",
    "val_labels = test_val_labels_split[1];\n",
    "\n",
    "train_images.shape, test_images.shape, val_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "With the done of the data preprocessing, I will do Data Preparation using TensorLayerX's API. This part is crucial since we can't just set the data into the model without reshaping it into proper tensor format.\n",
    "\n",
    "As mentioned above, we know that the images consists of data dimension below:\n",
    "\n",
    "| Attribute | Size |\n",
    "|---|---|\n",
    "| Width | 28px |\n",
    "| Height | 28px |\n",
    "| Color Channels | Gray Scale |\n",
    "\n",
    "With this information above, we can conclude that the tensor dimension should be (28 -> Width, 28 -> Height, 1 -> Color Channel). Which is, not same as the loaded version that was (28, 28).\n",
    "\n",
    "The data preparation is done using Data Loading pattern. This pattern will encapsulating the process of loading and preprocessing data. Since the rest of data pre-processing phase below will manipulating the nature of the data, like converting it to some data format, it is best to encapsulating it into a class. \n",
    "\n",
    "So what we will do in this part are:\n",
    "\n",
    "1. Set Tensorlayerx's backend as Tensorflow / Torch\n",
    "2. Create Data Loader class\n",
    "3. Converts every value within features with shape of (28, 28, 1) and as float32 tensor since it is easier to model to read.\n",
    "4. Standardize the data within features by dividing it to 255.\n",
    "5. Register all train-test-val data with Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\Users\\yosua\\anaconda3\\envs\\tlx-obor\\Lib\\site-packages\\tensorlayerx\\__init__.py:45: UserWarning: The version of the backend you have installed does not match the specified backend version and may not work, please install version tensorflow 2.4.0.\n",
      "  warnings.warn(\"The version of the backend you have installed does not match the specified backend version \"\n"
     ]
    }
   ],
   "source": [
    "import tensorlayerx;\n",
    "from tensorlayerx import expand_dims, convert_to_tensor, float32, squeeze;\n",
    "from tensorlayerx.dataflow import IterableDataset;\n",
    "\n",
    "import os;\n",
    "\n",
    "# Set Tensorlayerx's backend as Tensorflow / Torch\n",
    "# os.environ[\"TL_BACKEND\"] = \"tensorflow\"; # Uncomment this line to use Tensorflow's Backend\n",
    "os.environ[\"TL_BACKEND\"] = \"torch\"; # Uncomment this line to use Torch's backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Loader class\n",
    "class DatasetLoader(IterableDataset):\n",
    "    def __init__(self, feature, label):\n",
    "\n",
    "        # Converts every value within features with shape of (28, 28, 1) and as float32 tensor since it is easier to model to read.\n",
    "        # Standardize the data within features by dividing it to 255.\n",
    "        self.data = feature.reshape((len(feature), 28, 28, 1)).astype('float32') / 255;\n",
    "        self.label = label.astype('int32');\n",
    "    \n",
    "        print(f\"Data Shape: {self.data.shape}\");\n",
    "        print(f\"Label Shape: {self.label.shape}\");\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index];\n",
    "        label = self.label[index];\n",
    "\n",
    "        return data, label;\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data);\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self.data)):\n",
    "            yield self.data[i], self.label[i];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (60000, 28, 28, 1)\n",
      "Label Shape: (60000,)\n",
      "Data Shape: (5000, 28, 28, 1)\n",
      "Label Shape: (60000,)\n",
      "Data Shape: (5000, 28, 28, 1)\n",
      "Label Shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Register all train-test-val data with Data Loader\n",
    "\n",
    "train_set = DatasetLoader(train_images, train_labels);\n",
    "test_set = DatasetLoader(test_images, train_labels);\n",
    "val_set = DatasetLoader(val_images, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28, 1), 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, label = val_set.__getitem__(0);\n",
    "\n",
    "data.shape, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "GAN architecture consist of 2 Models. Generator, and Discriminator. \n",
    "\n",
    "Generator model inteded to be generate the *fake* hand written. By mean *fake*, means that the model will generate new hand written digit sample. \n",
    "Discriminator model intended for telling us whether the generated image are right or not. \n",
    "\n",
    "With these information aboves, we can assume that both generator and discriminator model must have at least these architectures as follow:\n",
    "\n",
    "1. Generator\n",
    "\n",
    "| Layer type | Specification | Purpose |\n",
    "|---|---|---|\n",
    "| Input Layer | Dense -> Shape (100, ) | This contains the random noise data for initializing the weight distribution for the model. |\n",
    "| Output Layer |  Conv2d -> Shape (28, 28, 1) | The drawing result from the model. |\n",
    "\n",
    "2. Discriminator\n",
    "\n",
    "| Layer type | Specification | Purpose |\n",
    "|---|---|---|\n",
    "| Input Layer | Conv2d -> Shape (28, 28, 1) | This is must be matched with Generator's output |\n",
    "| Output Layer | Linear -> Shape (1) | This is boolean. Truthy or falsy. Determine whether the generated image from Generator is fake or not. |\n",
    "\n",
    "Before we jumping into "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorlayerx.nn import Module, Conv2d, Linear, BatchNorm, MaxPool2d, Flatten, Input, Reshape, ConvTranspose2d;\n",
    "from tensorlayerx import LeakyReLU, Tanh, Sigmoid;\n",
    "from tensorlayerx.metrics import Accuracy;\n",
    "from tensorlayerx.losses import binary_cross_entropy;\n",
    "\n",
    "import numpy;\n",
    "\n",
    "import tensorlayerx as tlx;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Model\n",
    "\n",
    "class MNIST_Model_G(Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MNIST_Model_G, self).__init__();\n",
    "\n",
    "        # I don't know why this can't be from tlx.initializers import TruncatedNormal\n",
    "        w_init = tlx.initializers.TruncatedNormal(stddev = 0.02);\n",
    "        b_init = tlx.initializers.TruncatedNormal(mean = 1.0, stddev = 0.02);\n",
    "    \n",
    "        self.input = Input(shape = (None, 100,));\n",
    "        \n",
    "        self.dense1 = Linear(7 * 7 * 256, b_init = b_init);\n",
    "        self.bn1 = BatchNorm();\n",
    "        self.act1 = LeakyReLU();\n",
    "        self.reshape1 = Reshape(shape = (7, 7, 256));\n",
    "        self.conv_trans1 = ConvTranspose2d(out_channels = 128, kernel_size = (5, 5), stride = (1, 1), padding = \"SAME\", b_init = b_init);\n",
    "        self.reshape2 = Reshape(shape = (7, 7, 128));\n",
    "        self.bn2 = BatchNorm();\n",
    "        self.act2 = LeakyReLU();\n",
    "        self.conv_trans2 = ConvTranspose2d(out_channels = 64, kernel_size = (5, 5), stride = (2, 2), padding = \"SAME\", b_init = b_init);\n",
    "        self.reshape3 = Reshape(shape = (14, 14, 64));\n",
    "        self.bn3 = BatchNorm();\n",
    "        self.act3 = LeakyReLU();\n",
    "        self.conv_trans3 = ConvTranspose2d(out_channels = 1, kernel_size = (5, 5), act = Tanh, stride = (2, 2), padding = \"SAME\", b_init = b_init);\n",
    "        self.output = Reshape(shape = (28, 28, 1));\n",
    "        \n",
    "\n",
    "        # self.input = Input(shape = (64, 28, 28, 1));\n",
    "        # self.conv1 = Conv2d(out_channels = 64, kernel_size = (3, 3), act = LeakyReLU, padding = \"SAME\", W_init = w_init, b_init = b_init, data_format = \"channel_first\", name = \"conv1\");\n",
    "        # self.conv2 = Conv2d(out_channels = 64, kernel_size = (3, 3), act = LeakyReLU, padding = \"SAME\", W_init = w_init, b_init = b_init, data_format = \"channel_first\", name = \"conv2\");\n",
    "        \n",
    "        # self.output = Conv2d(out_channels = 1, kernel_size = (1, 1), act = Tanh, padding = \"SAME\", W_init = w_init, b_init = b_init, data_format = \"channel_first\", name = \"output\");\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense1(x);\n",
    "        x = self.bn1(x);\n",
    "        x = self.act1(x);\n",
    "        x = self.reshape1(x);\n",
    "\n",
    "        x = self.conv_trans1(x);\n",
    "        x = self.reshape2(x);\n",
    "        x = self.bn2(x);\n",
    "        x = self.act2(x);\n",
    "\n",
    "        x = self.conv_trans2(x);\n",
    "        x = self.reshape3(x);\n",
    "        x = self.bn3(x);\n",
    "        x = self.act3(x);\n",
    "\n",
    "        x = self.conv_trans3(x);\n",
    "\n",
    "        x = self.output(x);\n",
    "\n",
    "        return x;\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.input(x);\n",
    "        x = self.dense1(x);\n",
    "        x = self.bn1(x);\n",
    "        x = self.act1(x);\n",
    "        x = self.reshape1(x);\n",
    "\n",
    "        x = self.conv_trans1(x);\n",
    "        x = self.reshape2(x);\n",
    "        x = self.bn2(x);\n",
    "        x = self.act2(x);\n",
    "\n",
    "        x = self.conv_trans2(x);\n",
    "        x = self.reshape3(x);\n",
    "        x = self.bn3(x);\n",
    "        x = self.act3(x);\n",
    "\n",
    "        x = self.conv_trans3(x);\n",
    "        \n",
    "        out = self.output(x);\n",
    "\n",
    "        return out;\n",
    "\n",
    "class G_With_Loss(Module):\n",
    "    def __init__(self, G_Net: Module, D_Net: Module, loss_fn):\n",
    "        super(G_With_Loss, self).__init__();\n",
    "\n",
    "        self.G_Net = G_Net;\n",
    "        self.D_Net = D_Net;\n",
    "        self.loss_function = loss_fn;\n",
    "\n",
    "    def forward(self, data, ground_truth):\n",
    "        fake_image = self.G_Net(data);\n",
    "        logits_fake = self.D_Net(fake_image);\n",
    "\n",
    "        loss = self.loss_function(logits_fake, ground_truth);\n",
    "\n",
    "        return loss;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Model_D(Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MNIST_Model_D, self).__init__();\n",
    "\n",
    "        # I don't know why this can't be from tlx.initializers import TruncatedNormal\n",
    "        w_init = tlx.initializers.TruncatedNormal(stddev = 0.02);\n",
    "        b_init = tlx.initializers.TruncatedNormal(mean = 1.0, stddev = 0.02);\n",
    "\n",
    "        self.input = Input(shape = (28, 28, 1));\n",
    "        \n",
    "        self.conv1 = Conv2d(out_channels = 64, kernel_size = (3, 3), act = LeakyReLU, padding = \"SAME\", W_init = w_init, b_init = b_init, data_format = \"channel_first\", name = \"conv1\");\n",
    "        self.pool1 = MaxPool2d(kernel_size = (2, 2), name = \"pool1\");\n",
    "\n",
    "        self.conv2 = Conv2d(out_channels = 32, kernel_size = (3, 3), act = LeakyReLU, padding = \"SAME\", W_init = w_init, b_init = b_init, data_format = \"channel_first\", name = \"conv2\");\n",
    "        self.pool2 = MaxPool2d(kernel_size = (2, 2), name = \"pool2\");\n",
    "\n",
    "        self.flat = Flatten(name = \"flat\");\n",
    "        self.output = Linear(\n",
    "            out_features = 1,\n",
    "            W_init = tlx.initializers.TruncatedNormal(stddev = 5e-2),\n",
    "            b_init = tlx.initializers.TruncatedNormal(mean = 1, stddev = 2e-2),\n",
    "            act = Sigmoid,\n",
    "            name = \"output\"\n",
    "        );\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x);\n",
    "        x = self.pool1(x);\n",
    "        \n",
    "        x = self.conv2(x);\n",
    "        x = self.pool2(x);\n",
    "\n",
    "        x = self.flat(x);\n",
    "        x = self.output(x);\n",
    "\n",
    "        return x;\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.input(x);\n",
    "\n",
    "        x = self.conv1(x);\n",
    "        x = self.pool1(x);\n",
    "        \n",
    "        x = self.conv2(x);\n",
    "        x = self.pool2(x);\n",
    "\n",
    "        x = self.flat(x);\n",
    "        out = self.output(x);\n",
    "\n",
    "        return out;\n",
    "\n",
    "class D_With_Loss(Module):\n",
    "    def __init__(self, G_Net: Module, D_Net: Module, loss_fn):\n",
    "        super(D_With_Loss, self).__init__();\n",
    "\n",
    "        self.G_Net = G_Net;\n",
    "        self.D_Net = D_Net;\n",
    "        self.loss_function = loss_fn;\n",
    "\n",
    "\n",
    "    def forward(self, real_data, fake_data):\n",
    "        logits_real = self.D_Net(real_data);\n",
    "\n",
    "        fake_image = self.G_Net(fake_data);\n",
    "        logits_fake = self.D_Nate(fake_image);\n",
    "\n",
    "        valid = tlx.convert_to_tensor(numpy.ones(logits_real.shape), dtype = tlx.float32);\n",
    "        fake = tlx.convert_to_tensor(numpy.ones(logits_fake.shape), dtype = tlx.float32);\n",
    "\n",
    "        loss = self.loss_function(logits_real, valid) + self.loss_function(logits_fake, fake);\n",
    "\n",
    "        return loss;\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Training\n",
    "\n",
    "As per this code being typed, I believe that every adversarial training use case required different treatment. MNIST for example, the G network must be init with set of randomized numbers as initializer, and then being fed to model. \n",
    "\n",
    "There are 2 trainings to be done in here:\n",
    "\n",
    "1. G initialization\n",
    "This will actually train the Generator model to make fake samples.\n",
    "\n",
    "2. Adversarial Training\n",
    "This will "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorlayerx.model import TrainOneStep; \n",
    "from tensorlayerx.optimizers import SGD;\n",
    "\n",
    "from tqdm import tqdm;\n",
    "from time import time;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TLX] Input  _inputlayer_3: (None, 100)\n",
      "[TLX] Linear  linear_2: 12544 No Activation\n",
      "[TLX] BatchNorm batchnorm_4: momentum: 0.900000 epsilon: 0.000010 act: No Activation is_train: True\n",
      "[TLX] Reshape reshape_5\n",
      "[TLX] ConvTranspose2d convtranspose2d_4: out_channels: 128 kernel_size: (5, 5) stride: (1, 1) pad: SAME act: No Activation output_padding: 0 groups: 1\n",
      "[TLX] Reshape reshape_6\n",
      "[TLX] BatchNorm batchnorm_5: momentum: 0.900000 epsilon: 0.000010 act: No Activation is_train: True\n",
      "[TLX] ConvTranspose2d convtranspose2d_5: out_channels: 64 kernel_size: (5, 5) stride: (2, 2) pad: SAME act: No Activation output_padding: 0 groups: 1\n",
      "[TLX] Reshape reshape_7\n",
      "[TLX] BatchNorm batchnorm_6: momentum: 0.900000 epsilon: 0.000010 act: No Activation is_train: True\n",
      "[TLX] ConvTranspose2d convtranspose2d_6: out_channels: 1 kernel_size: (5, 5) stride: (2, 2) pad: SAME act: Tanh output_padding: 0 groups: 1\n",
      "[TLX] Reshape reshape_8\n",
      "[TLX] Input  _inputlayer_4: (28, 28, 1)\n",
      "[TLX] Conv2d conv1: out_channels : 64 kernel_size: (3, 3) stride: (1, 1) pad: SAME act: LeakyReLU\n",
      "[TLX] MaxPool2d pool1: kernel_size: (2, 2) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Conv2d conv2: out_channels : 32 kernel_size: (3, 3) stride: (1, 1) pad: SAME act: LeakyReLU\n",
      "[TLX] MaxPool2d pool2: kernel_size: (2, 2) stride: (2, 2) padding: SAME return_mask: False\n",
      "[TLX] Flatten flat:\n",
      "[TLX] Linear  output: 1 Sigmoid\n"
     ]
    }
   ],
   "source": [
    "mse = tlx.losses.mean_squared_error;\n",
    "\n",
    "# Training Config\n",
    "epoch = 10;\n",
    "generator = MNIST_Model_G();\n",
    "discriminator = MNIST_Model_D();\n",
    "\n",
    "G_With_Loss = G_With_Loss(generator, discriminator, mse);\n",
    "D_With_Loss = D_With_Loss(generator, discriminator, mse);\n",
    "\n",
    "G_trainer = TrainOneStep(G_With_Loss, SGD(), generator.trainable_weights);\n",
    "D_trainer = TrainOneStep(D_With_Loss, SGD(), discriminator.trainable_weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1 / 10 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_set):\n\u001b[0;32m     23\u001b[0m     noise \u001b[38;5;241m=\u001b[39m tlx\u001b[38;5;241m.\u001b[39mconvert_to_tensor(numpy\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal([\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m100\u001b[39m]), dtype \u001b[38;5;241m=\u001b[39m tlx\u001b[38;5;241m.\u001b[39mfloat32);\n\u001b[1;32m---> 25\u001b[0m     D_loss \u001b[38;5;241m=\u001b[39m \u001b[43mD_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[0;32m     26\u001b[0m     G_loss \u001b[38;5;241m=\u001b[39m G_trainer(noise, y_batch);\n\u001b[0;32m     28\u001b[0m     train_D_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m D_loss;\n",
      "File \u001b[1;32mc:\\Users\\yosua\\anaconda3\\envs\\tlx-obor\\Lib\\site-packages\\tensorlayerx\\model\\core.py:637\u001b[0m, in \u001b[0;36mTrainOneStep.__call__\u001b[1;34m(self, data, label, *args, **kwargs)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, label, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 637\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet_with_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\yosua\\anaconda3\\envs\\tlx-obor\\Lib\\site-packages\\tensorlayerx\\model\\utils.py:140\u001b[0m, in \u001b[0;36mTrainOneStepWithTF.__call__\u001b[1;34m(self, data, label, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, label, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m--> 140\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet_with_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     grad \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_weights)\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grad, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_weights))\n",
      "File \u001b[1;32mc:\\Users\\yosua\\anaconda3\\envs\\tlx-obor\\Lib\\site-packages\\tensorlayerx\\nn\\core\\core_tensorflow.py:173\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_weights_check()\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "Cell \u001b[1;32mIn[16], line 63\u001b[0m, in \u001b[0;36mD_With_Loss.forward\u001b[1;34m(self, real_data, fake_data)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, real_data, fake_data):\n\u001b[1;32m---> 63\u001b[0m     logits_real \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mD_Net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_data\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[0;32m     65\u001b[0m     fake_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mG_Net(fake_data);\n\u001b[0;32m     66\u001b[0m     logits_fake \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD_Nate(fake_image);\n",
      "File \u001b[1;32mc:\\Users\\yosua\\anaconda3\\envs\\tlx-obor\\Lib\\site-packages\\tensorlayerx\\nn\\core\\core_tensorflow.py:173\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_weights_check()\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "Cell \u001b[1;32mIn[16], line 28\u001b[0m, in \u001b[0;36mMNIST_Model_D.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 28\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[0;32m     29\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(x);\n\u001b[0;32m     31\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x);\n",
      "File \u001b[1;32mc:\\Users\\yosua\\anaconda3\\envs\\tlx-obor\\Lib\\site-packages\\tensorlayerx\\nn\\core\\core_tensorflow.py:173\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_weights_check()\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\yosua\\anaconda3\\envs\\tlx-obor\\Lib\\site-packages\\tensorlayerx\\nn\\layers\\convolution\\simplified_conv.py:289\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_state \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_built \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m--> 289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild(\u001b[43mtlx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tensor_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_built \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yosua\\anaconda3\\envs\\tlx-obor\\Lib\\site-packages\\tensorlayerx\\backend\\ops\\tensorflow_backend.py:88\u001b[0m, in \u001b[0;36mget_tensor_shape\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_tensor_shape\u001b[39m(x):\n\u001b[0;32m     68\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    Get the shape of tensor\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m \n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_shape\u001b[49m()\u001b[38;5;241m.\u001b[39mas_list()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'get_shape'"
     ]
    }
   ],
   "source": [
    "progress_epoch = [];\n",
    "progress_train_G_loss = [];\n",
    "progress_train_D_loss = [];\n",
    "progress_train_G_acc = [];\n",
    "progress_train_D_acc = [];\n",
    "progress_val_G_loss = [];\n",
    "progress_val_D_loss = [];\n",
    "progress_val_G_acc = [];\n",
    "progress_val_D_acc = [];\n",
    "\n",
    "for i in range(epoch):\n",
    "    start_time = time();\n",
    "    print(f\"Training Epoch {i+1} / {epoch}\", end = \" \");\n",
    "\n",
    "    # Training phase\n",
    "    generator.set_train();\n",
    "    discriminator.set_train();\n",
    "    train_n_iter = 0;\n",
    "    train_D_loss, train_D_acc = 0, 0;\n",
    "    train_G_loss, train_G_acc = 0, 0;\n",
    "\n",
    "    for X_batch, y_batch in tqdm(train_set):\n",
    "        noise = tlx.convert_to_tensor(numpy.random.normal([256, 100]), dtype = tlx.float32);\n",
    "\n",
    "        D_loss = D_trainer(X_batch, noise);\n",
    "        G_loss = G_trainer(noise, y_batch);\n",
    "\n",
    "        train_D_loss += D_loss;\n",
    "        train_G_loss += G_loss;\n",
    "        train_n_iter += 1;\n",
    "\n",
    "        # Calculate accuracy\n",
    "        # metric_train.update(logits, y_batch);\n",
    "        # train_acc += metric_train.result();\n",
    "        # metric_train.reset();\n",
    "\n",
    "    # Validation phase\n",
    "\n",
    "    # network.set_eval();\n",
    "    # val_loss, val_acc, val_n_iter = 0, 0, 0;\n",
    "\n",
    "    # for X_batch, y_batch in val_set_loader:\n",
    "    #     loss = trainer(X_batch, y_batch);\n",
    "    #     val_loss += loss;\n",
    "\n",
    "    #     val_n_iter += 1;\n",
    "\n",
    "    #     logits = network(X_batch);\n",
    "\n",
    "    #     # Calculate accuracy\n",
    "    #     metric_val.update(logits, y_batch);\n",
    "    #     val_acc += metric_val.result();\n",
    "        # metric_val.reset();\n",
    "\n",
    "    time_done = (int)(time() - start_time);\n",
    "\n",
    "    train_D_loss = train_D_loss / train_n_iter;\n",
    "    train_G_loss = train_G_loss / train_n_iter;\n",
    "    # val_loss = val_loss / val_n_iter;\n",
    "    # val_acc = val_acc / val_n_iter;\n",
    "\n",
    "    progress_epoch.append(i+1);\n",
    "    progress_train_D_loss.append(train_D_loss);\n",
    "    progress_train_G_loss.append(train_G_loss);\n",
    "    # progress_val_acc.append(val_acc);\n",
    "    # progress_val_loss.append(val_loss);\n",
    "\n",
    "    print(f\"Epoch {i+1} - {time_done}s - train D loss: {train_D_loss} - train G loss: {train_G_loss}\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tlx-obor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
